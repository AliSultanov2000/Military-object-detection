{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ë–µ–π–∑–ª–∞–π–Ω –¥–ª—è –∑–∞–¥–∞—á–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import torch\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO, RTDETR\n",
    "sys.path.append(r\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1080, 8192MiB)\n",
      "Setup complete ‚úÖ (4 CPUs, 31.9 GB RAM, 440.9/930.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ–≤–∞–π—Å\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "model_path = r\"\"\n",
    "model = YOLO(model_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ü—Ä–æ—Ö–æ–¥ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detection(image_path: str) -> None:\n",
    "    \"\"\"–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\"\"\"\n",
    "                           \n",
    "    results = model(image_path)  # Results list\n",
    "    # Show the results\n",
    "    for result in results:\n",
    "        im_array = result.plot()  # Plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        im.show()  # Show image\n",
    "\n",
    "\n",
    "# –¢–µ—Å—Ç\n",
    "image_detection(r\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ü—Ä–æ—Ö–æ–¥ –Ω–∞ –≤–∏–¥–µ–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_detection(video_path: str) -> None:\n",
    "    \"\"\"\n",
    "    –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –≤–∏–¥–µ–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ \n",
    "    —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–µ–π –Ω–∞ –∑–∞–¥–∞—á–µ –¥–µ—Ç–µ–∫—Ü–∏–∏\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            results = model.predict(frame)\n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            cv2.imshow(\"YOLO Inference\", annotated_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# –¢–µ—Å—Ç\n",
    "stream_detection(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
